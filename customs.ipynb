{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing as housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(55)\n",
    "tf.random.set_seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X.data, X.target.reshape(-1, 1))\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full.reshape(-1, 1))\n",
    "\n",
    "X_mean = X_train.mean(axis=0)\n",
    "X_std = X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - X_mean)/X_std\n",
    "X_valid_scaled = (X_valid - X_mean)/X_std\n",
    "X_test_scaled = (X_test - X_mean)/X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_train_scaled.shape == X_train.shape\n",
    "assert X_valid_scaled.shape == X_valid.shape\n",
    "assert X_test_scaled.shape == X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def my_relu(x):\n",
    "    return tf.math.maximum(0., x)\n",
    "\n",
    "@tf.function\n",
    "def my_elu(x):\n",
    "    return tf.where(x>=0, x, tf.exp(x)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlorotNormal(tf.keras.initializers.Initializer):\n",
    "    def __init__(self, mean=0., stddev=1.):\n",
    "        self.mean = mean\n",
    "        self.stddev = stddev\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        return tf.random.normal(\n",
    "            shape, mean=self.mean, stddev=self.stddev, dtype=dtype)\n",
    "    def get_config(self):\n",
    "        return {\"mean\": self.mean, \"stddev\": self.stddev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZerosInitializer(tf.keras.initializers.Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        return tf.zeros(shape=shape, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_Dense(keras.layers.Layer):\n",
    "    def __init__(self, units=1, \n",
    "                 activation=None, \n",
    "                 use_bias=True, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        if activation:\n",
    "            if activation==\"relu\":\n",
    "                self.activation = my_relu\n",
    "            elif activation==\"elu\":\n",
    "                self.activation = my_elu\n",
    "        else:\n",
    "            self.activation=(lambda x: x)\n",
    "        self.use_bias=use_bias\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        print(\"hello\", type(input_shape[0]), type(input_shape[1]), type(input_shape))\n",
    "        shape = (input_shape[-1], self.units)\n",
    "        stddev = tf.sqrt(2. / (input_shape[-1]+self.units))\n",
    "        weight_init = GlorotNormal(stddev=stddev)\n",
    "        self.kernel = tf.Variable(\n",
    "            initial_value=weight_init(shape=shape, \n",
    "                                      dtype='float32'), trainable=self.trainable)\n",
    "        if self.use_bias:\n",
    "            bias_init = ZerosInitializer()\n",
    "            self.bias = tf.Variable(\n",
    "                initial_value=bias_init(shape=(self.units), \n",
    "                                        dtype='float32'), trainable=self.trainable)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "#         super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.activation(inputs @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [input_shape[0], self.units]\n",
    "\n",
    "    def get_config(self):\n",
    "        super_config = super().get_config()\n",
    "        return {**super_config, \n",
    "                \"units\": self.units, \n",
    "                \"activation\": activation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_nDense(keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 units=1, \n",
    "                 n_layers=1, \n",
    "                 activation=None, \n",
    "                 use_bias=True, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.n_layers=n_layers\n",
    "        self.activation=activation\n",
    "        self.hidden= [custom_Dense(units=units, \n",
    "                                  activation=activation, \n",
    "                                  use_bias=use_bias) \n",
    "                      for _ in range(self.n_layers)]\n",
    "        \n",
    "    def call(self, X):\n",
    "        Z = X\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return Z\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [input_shape[0], self.units]\n",
    "    \n",
    "    def get_config(self):\n",
    "        super_config = super().get_config()\n",
    "        return {**super_config, \n",
    "                \"units\":self.units, \n",
    "                \"activation\":self.activation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, \n",
    "                 output_dim=1, \n",
    "                 **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = custom_nDense(units=100, n_layers=1, activation=\"relu\")\n",
    "        self.out = custom_Dense(units=output_dim)\n",
    "        \n",
    "    def call(self, X):\n",
    "        Z = self.hidden1(X)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_TF_MODULE_IGNORED_PROPERTIES',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_inbound_node',\n",
       " '_add_trackable',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_assert_compile_was_called',\n",
       " '_assert_weights_created',\n",
       " '_attribute_sentinel',\n",
       " '_base_init',\n",
       " '_call_accepts_kwargs',\n",
       " '_call_arg_was_passed',\n",
       " '_call_fn_args',\n",
       " '_call_full_argspec',\n",
       " '_check_call_args',\n",
       " '_checkpoint_dependencies',\n",
       " '_clear_losses',\n",
       " '_collect_input_masks',\n",
       " '_compile_was_called',\n",
       " '_compute_dtype',\n",
       " '_compute_tensor_usage_count',\n",
       " '_conform_to_reference_input',\n",
       " '_dedup_weights',\n",
       " '_deferred_dependencies',\n",
       " '_dtype',\n",
       " '_eager_add_metric',\n",
       " '_eager_losses',\n",
       " '_flatten',\n",
       " '_flatten_to_reference_inputs',\n",
       " '_gather_children_attribute',\n",
       " '_gather_layers',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_gather_unique_layers',\n",
       " '_get_call_arg_value',\n",
       " '_get_callback_model',\n",
       " '_get_compile_args',\n",
       " '_get_distribution_strategy',\n",
       " '_get_existing_metric',\n",
       " '_get_node_attribute_at_index',\n",
       " '_get_optimizer',\n",
       " '_get_save_spec',\n",
       " '_get_trainable_state',\n",
       " '_graph_network_add_loss',\n",
       " '_graph_network_add_metric',\n",
       " '_handle_activity_regularization',\n",
       " '_handle_deferred_dependencies',\n",
       " '_handle_deferred_layer_dependencies',\n",
       " '_handle_weight_regularization',\n",
       " '_in_multi_worker_mode',\n",
       " '_init_call_fn_args',\n",
       " '_init_graph_network',\n",
       " '_init_set_name',\n",
       " '_init_subclassed_network',\n",
       " '_insert_layers',\n",
       " '_is_layer',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_layer_checkpoint_dependencies',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_maybe_build',\n",
       " '_maybe_cast_inputs',\n",
       " '_maybe_create_attribute',\n",
       " '_maybe_initialize_trackable',\n",
       " '_maybe_load_initial_epoch_from_ckpt',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_name_scope',\n",
       " '_no_dependency',\n",
       " '_obj_reference_counts',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_reset_compile_cache',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_run_internal_graph',\n",
       " '_set_connectivity_metadata_',\n",
       " '_set_dtype_policy',\n",
       " '_set_inputs',\n",
       " '_set_mask_metadata',\n",
       " '_set_output_names',\n",
       " '_set_save_spec',\n",
       " '_set_trainable_state',\n",
       " '_setattr_tracking',\n",
       " '_should_compute_mask',\n",
       " '_should_eval',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_symbolic_add_metric',\n",
       " '_symbolic_call',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_track_trackable',\n",
       " '_trackable_saved_model_saver',\n",
       " '_tracking_metadata',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_undeduplicated_weights',\n",
       " '_update_uid',\n",
       " '_updated_config',\n",
       " '_validate_compile',\n",
       " '_validate_graph_inputs_and_outputs',\n",
       " '_warn_about_input_casting',\n",
       " 'activity_regularizer',\n",
       " 'add_loss',\n",
       " 'add_metric',\n",
       " 'add_update',\n",
       " 'add_variable',\n",
       " 'add_weight',\n",
       " 'apply',\n",
       " 'build',\n",
       " 'call',\n",
       " 'compile',\n",
       " 'compute_mask',\n",
       " 'compute_output_shape',\n",
       " 'compute_output_signature',\n",
       " 'count_params',\n",
       " 'distribute_strategy',\n",
       " 'dtype',\n",
       " 'dynamic',\n",
       " 'evaluate',\n",
       " 'evaluate_generator',\n",
       " 'fit',\n",
       " 'fit_generator',\n",
       " 'from_config',\n",
       " 'get_config',\n",
       " 'get_input_at',\n",
       " 'get_input_mask_at',\n",
       " 'get_input_shape_at',\n",
       " 'get_layer',\n",
       " 'get_losses_for',\n",
       " 'get_output_at',\n",
       " 'get_output_mask_at',\n",
       " 'get_output_shape_at',\n",
       " 'get_updates_for',\n",
       " 'get_weights',\n",
       " 'inbound_nodes',\n",
       " 'input',\n",
       " 'input_mask',\n",
       " 'input_shape',\n",
       " 'input_spec',\n",
       " 'layers',\n",
       " 'load_weights',\n",
       " 'losses',\n",
       " 'make_predict_function',\n",
       " 'make_test_function',\n",
       " 'make_train_function',\n",
       " 'metrics',\n",
       " 'metrics_names',\n",
       " 'name',\n",
       " 'name_scope',\n",
       " 'non_trainable_variables',\n",
       " 'non_trainable_weights',\n",
       " 'outbound_nodes',\n",
       " 'output',\n",
       " 'output_mask',\n",
       " 'output_shape',\n",
       " 'predict',\n",
       " 'predict_generator',\n",
       " 'predict_on_batch',\n",
       " 'predict_step',\n",
       " 'reset_metrics',\n",
       " 'reset_states',\n",
       " 'run_eagerly',\n",
       " 'save',\n",
       " 'save_weights',\n",
       " 'set_weights',\n",
       " 'state_updates',\n",
       " 'stateful',\n",
       " 'submodules',\n",
       " 'summary',\n",
       " 'test_on_batch',\n",
       " 'test_step',\n",
       " 'to_json',\n",
       " 'to_yaml',\n",
       " 'train_on_batch',\n",
       " 'train_step',\n",
       " 'trainable',\n",
       " 'trainable_variables',\n",
       " 'trainable_weights',\n",
       " 'updates',\n",
       " 'variables',\n",
       " 'weights',\n",
       " 'with_name_scope']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(MyModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(55)\n",
    "tf.random.set_seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-4), metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "hello <class 'int'> <class 'int'> <class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n",
      "hello <class 'int'> <class 'int'> <class 'tensorflow.python.framework.tensor_shape.TensorShape'>\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 3.5285 - mae: 1.5200 - val_loss: 1.9845 - val_mae: 1.0458\n",
      "Epoch 2/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 1.4947 - mae: 0.8828 - val_loss: 1.1116 - val_mae: 0.7433\n",
      "Epoch 3/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.9800 - mae: 0.7175 - val_loss: 0.8244 - val_mae: 0.6560\n",
      "Epoch 4/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.8075 - mae: 0.6608 - val_loss: 0.7112 - val_mae: 0.6213\n",
      "Epoch 5/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.7383 - mae: 0.6338 - val_loss: 0.6616 - val_mae: 0.6040\n",
      "Epoch 6/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.7051 - mae: 0.6188 - val_loss: 0.6352 - val_mae: 0.5932\n",
      "Epoch 7/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6852 - mae: 0.6086 - val_loss: 0.6187 - val_mae: 0.5845\n",
      "Epoch 8/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6706 - mae: 0.6002 - val_loss: 0.6065 - val_mae: 0.5776\n",
      "Epoch 9/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6585 - mae: 0.5934 - val_loss: 0.5964 - val_mae: 0.5712\n",
      "Epoch 10/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6477 - mae: 0.5869 - val_loss: 0.5873 - val_mae: 0.5662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf106006a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_valid_scaled, y_valid), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.custom_nDense at 0x7fdf12e6f550>,\n",
       " <__main__.custom_Dense at 0x7fdf12e6fc40>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "custom_n_dense (custom_nDens multiple                  900       \n",
      "_________________________________________________________________\n",
      "custom__dense_1 (custom_Dens multiple                  101       \n",
      "=================================================================\n",
      "Total params: 1,001\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01105039e+00, -6.98123209e-01, -1.94180473e-01, ...,\n",
       "         2.92666074e-01,  4.22302244e-01, -4.57247389e-01],\n",
       "       [ 7.46565256e-03, -6.98123209e-01,  1.67477270e-01, ...,\n",
       "         4.81086670e-02,  1.30748079e+00, -1.56103408e+00],\n",
       "       [ 6.62417881e-01, -9.37182054e-01,  2.34491761e-01, ...,\n",
       "         1.62800374e-03, -8.46922025e-01,  8.55363807e-01],\n",
       "       ...,\n",
       "       [ 2.30366463e-01,  1.85183780e+00,  3.67541077e-01, ...,\n",
       "        -9.94059513e-02, -7.20467947e-01,  7.16147468e-01],\n",
       "       [ 1.10895706e+00, -9.37182054e-01,  1.81766465e-01, ...,\n",
       "        -9.77141916e-03,  7.59513119e-01, -1.19310518e+00],\n",
       "       [ 6.04993659e-01, -9.37182054e-01,  2.81134684e-01, ...,\n",
       "        -1.29788671e-02,  5.48756322e-01, -1.02902878e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(55)\n",
    "tf.random.set_seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "initializer=keras.initializers.GlorotNormal()\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=initializer))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-4), metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fdef86d6580>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fdef86d6d90>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 2.9706 - mae: 1.3388 - val_loss: 2.0143 - val_mae: 1.0008\n",
      "Epoch 2/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 1.4925 - mae: 0.8831 - val_loss: 1.2659 - val_mae: 0.7735\n",
      "Epoch 3/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 1.0426 - mae: 0.7443 - val_loss: 0.9347 - val_mae: 0.6881\n",
      "Epoch 4/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.8622 - mae: 0.6836 - val_loss: 0.7821 - val_mae: 0.6463\n",
      "Epoch 5/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.7802 - mae: 0.6504 - val_loss: 0.7099 - val_mae: 0.6234\n",
      "Epoch 6/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.7377 - mae: 0.6313 - val_loss: 0.6698 - val_mae: 0.6087\n",
      "Epoch 7/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.7114 - mae: 0.6187 - val_loss: 0.6463 - val_mae: 0.5980\n",
      "Epoch 8/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6920 - mae: 0.6088 - val_loss: 0.6292 - val_mae: 0.5894\n",
      "Epoch 9/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6759 - mae: 0.6003 - val_loss: 0.6154 - val_mae: 0.5816\n",
      "Epoch 10/10\n",
      "1161/1161 [==============================] - 2s 2ms/step - loss: 0.6616 - mae: 0.5924 - val_loss: 0.6031 - val_mae: 0.5753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf136fa4c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_valid_scaled, y_valid), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  900       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  101       \n",
      "=================================================================\n",
      "Total params: 1,001\n",
      "Trainable params: 1,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    metrics = \" - \".join([\"{}: {:.4f}\".format(m.name, m.result())\n",
    "                         for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - {}\".format(progress_bar(iteration, total), metrics), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - loss: 0.0900 - mean_square: 858.5000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 50 + 1):\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 50, mean_loss, [mean_square])\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "11610/11610 [==============================] - mean: 1.2608 - mean_absolute_error: 0.5807\n",
      "Epoch 2/5\n",
      "11610/11610 [==============================] - mean: 0.6838 - mean_absolute_error: 0.5412\n",
      "Epoch 3/5\n",
      "11610/11610 [==============================] - mean: 0.6820 - mean_absolute_error: 0.5465\n",
      "Epoch 4/5\n",
      "11610/11610 [==============================] - mean: 0.6599 - mean_absolute_error: 0.5399\n",
      "Epoch 5/5\n",
      "11610/11610 [==============================] - mean: 0.6698 - mean_absolute_error: 0.5424\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "#         if step == n_steps:\n",
    "#             print(\" \", type(main_loss), main_loss, type(model.losses), model.losses, sep=\"\\n\")\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#         if step == n_steps and epoch == n_epochs:\n",
    "#             print(\"\", type(gradients), len(gradients), gradients, sep=\"\\n\")\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.07555242>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.060151465>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
